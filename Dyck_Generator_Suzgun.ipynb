{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dyck_Generator_Suzgun.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3Je7jbv66WX9KZL8Hk/qS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadineelnaggar/NeSy_2021/blob/master/Dyck_Generator_Suzgun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8SJZ8_nW4jwy"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.setrecursionlimit(5000)\n",
        "\n",
        "all_pairs = ['()', '[]', '{}', '<>', '+-', 'ab', 'xo']\n",
        "all_letters = ''\n",
        "for elt in all_pairs:\n",
        "    all_letters += elt\n",
        "\n",
        "init_ascii = 48  ## corresponds to 0\n",
        "print(all_letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yyDs1yA43xa",
        "outputId": "6e79290a-5d56-4a62-e372-49fd959b1262"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()[]{}<>+-abxo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DyckLanguage():\n",
        "    def __init__(self, num_pairs, p, q):\n",
        "        self.pair_num = num_pairs\n",
        "        self.pairs = all_pairs[:num_pairs]\n",
        "        self.vocabulary = all_letters[:2 * num_pairs]\n",
        "        self.n_letters = len(self.vocabulary)\n",
        "\n",
        "        self.openpar = [elt[0] for elt in self.pairs]\n",
        "        self.closepar = [elt[1] for elt in self.pairs]\n",
        "\n",
        "        self.p = p\n",
        "        self.q = q\n",
        "\n",
        "    # returns the vocabulary\n",
        "    def return_vocab(self):\n",
        "        return self.vocabulary\n",
        "\n",
        "    # generate a sample\n",
        "    def generate(self, current_size, max_size):\n",
        "        # Houston, we have a problem here. (Limit exceeded.)\n",
        "        if current_size >= max_size:\n",
        "            return ''\n",
        "\n",
        "        prob = random.random()\n",
        "        # Grammar: S -> (_i S )_i with prob p | SS with prob q | empty with prob 1 - (p+q)\n",
        "        if prob < self.p:\n",
        "            chosen_pair = np.random.choice(self.pairs)  # randomly pick one of the pairs.\n",
        "            sample = chosen_pair[0] + self.generate(current_size + 2, max_size) + chosen_pair[1]\n",
        "            if len(sample) <= max_size:\n",
        "                return sample\n",
        "        elif prob < self.p + self.q:\n",
        "            sample = self.generate(current_size, max_size) + self.generate(current_size, max_size)\n",
        "            if len(sample) <= max_size:\n",
        "                return sample\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "        return ''\n",
        "\n",
        "    # generate 'num' number of samples\n",
        "    def generate_list(self, num, min_size, max_size):\n",
        "        arr = []\n",
        "        size_info = defaultdict(list)\n",
        "        counter = 0\n",
        "        while counter < num:\n",
        "            sample = self.generate(0, max_size)\n",
        "            if sample not in arr and len(sample) >= min_size:\n",
        "                counter += 1\n",
        "                arr.append(sample)\n",
        "                # print(sample) #extra added by me\n",
        "                size_info[len(sample)].append(sample)\n",
        "                if counter % 500 == 0:\n",
        "                    print('{} samples generated.'.format(counter))\n",
        "\n",
        "        return arr, size_info\n",
        "\n",
        "    def output_generator(self, seq):\n",
        "        output_seq = ''\n",
        "        stack = []\n",
        "\n",
        "        for elt in seq:\n",
        "            dyck_counter = [0 for _ in range(self.pair_num)]\n",
        "\n",
        "            if elt in self.openpar:\n",
        "                stack.append(self.closepar[self.openpar.index(elt)])\n",
        "            else:\n",
        "                stack.pop()\n",
        "\n",
        "            if len(stack) > 0:\n",
        "                index = self.closepar.index(stack[-1])\n",
        "                dyck_counter[index] = 1\n",
        "\n",
        "            temp = np.nonzero(dyck_counter)\n",
        "\n",
        "            binary_code = 0\n",
        "\n",
        "            for base in temp[0]:\n",
        "                binary_code += (2 ** (base))\n",
        "\n",
        "            output_seq += chr(binary_code + init_ascii)\n",
        "\n",
        "            # print(output_seq) #extra added by me \n",
        "\n",
        "        return output_seq\n",
        "\n",
        "    def depth_counter(self, seq):\n",
        "        dyck_counter = np.zeros(self.pair_num)\n",
        "        max_depth = np.zeros((len(seq), self.pair_num))\n",
        "        counter = 0\n",
        "        for elt in seq:\n",
        "            indexl = 0\n",
        "            if elt in self.openpar:\n",
        "                indexl = self.openpar.index(elt)\n",
        "                dyck_counter[indexl] += 1\n",
        "            else:\n",
        "                indexl = self.closepar.index(elt)\n",
        "                dyck_counter[indexl] -= 1\n",
        "            max_depth[counter] = dyck_counter\n",
        "            counter += 1\n",
        "        return max_depth\n",
        "\n",
        "    def training_set_generator(self, num, min_size, max_size):\n",
        "        input_arr, input_size_arr = self.generate_list(num, min_size, max_size)\n",
        "        output_arr = []\n",
        "        for seq in input_arr:\n",
        "           output_arr.append(self.output_generator(seq))\n",
        "        return input_arr, output_arr, input_size_arr\n",
        "        ##### CHANGED HERE\n",
        "        # return input_arr, input_size_arr\n",
        "\n",
        "    # Find letter index from all_letters\n",
        "    def letterToIndex(self, letter):\n",
        "        return all_letters.find(letter)\n",
        "\n",
        "    # Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "    def letterToTensor(self, letter):\n",
        "        tensor = torch.zeros(1, self.n_letters)\n",
        "        tensor[0][self.letterToIndex(letter)] = 1\n",
        "        return tensor\n",
        "\n",
        "    # Turn a line into a <line_length x 1 x n_letters>,\n",
        "    # or an array of one-hot letter vectors\n",
        "    def lineToTensor(self, line):\n",
        "        tensor = torch.zeros(len(line), 1, self.n_letters)\n",
        "        for li, letter in enumerate(line):\n",
        "            tensor[li][0][self.letterToIndex(letter)] = 1.0\n",
        "        return tensor\n",
        "\n",
        "    def lineToTensorSigmoid(self, line):\n",
        "        tensor = torch.zeros(len(line), self.n_letters)\n",
        "        for li, letter in enumerate(line):\n",
        "            for elt in self.openpar:\n",
        "                tensor[li][self.letterToIndex(elt)] = 1.0\n",
        "\n",
        "            binary_code = ord(letter) - init_ascii\n",
        "\n",
        "            if binary_code > 0:\n",
        "                for base in range(len(self.closepar) - 1, -1, -1):\n",
        "                    if binary_code - (2 ** base) >= 0:\n",
        "                        tensor[li][self.letterToIndex(self.closepar[base])] = 1.0\n",
        "                        binary_code -= (2 ** base)\n",
        "        return tensor"
      ],
      "metadata": {
        "id": "l7PUUM5U491z"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PAR = 1\n",
        "MIN_SIZE = 2\n",
        "MAX_SIZE = 50\n",
        "P_VAL = 0.5\n",
        "Q_VAL = 0.25"
      ],
      "metadata": {
        "id": "I1B7bl5450vS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dyck = DyckLanguage (NUM_PAR, P_VAL, Q_VAL)\n",
        "all_letters = word_set = Dyck.return_vocab ()\n",
        "n_letters = vocab_size = len (word_set)\n",
        "print(all_letters)\n",
        "print(n_letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC6m8-3B5-1P",
        "outputId": "72613b88-f7d4-4681-c798-f3dc2787787e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples in the training corpus\n",
        "TRAINING_SIZE = 10000\n",
        "# Number of samples in the test corpus\n",
        "TEST_SIZE = 5000\n",
        "print('Loading data...')\n",
        "\n",
        "# training_input, training_input_lengths = Dyck.training_set_generator (TRAINING_SIZE, MIN_SIZE, MAX_SIZE)\n",
        "# test_input, test_input_lenghts = Dyck.training_set_generator (TEST_SIZE, MAX_SIZE + 2, 2 * MAX_SIZE)\n",
        "\n",
        "\n",
        "training_input, training_output, training_input_lengths = Dyck.training_set_generator (TRAINING_SIZE, MIN_SIZE, MAX_SIZE)\n",
        "print('training data generated, writing training set to document')\n",
        "with open('Dyck1_Dataset_Suzgun_train.txt', 'a') as f:\n",
        "  for i in range(len(training_input)):\n",
        "    f.write(str(training_input[i])+','+str(training_output[i])+','+str(training_input_lengths[i])+'\\n')\n",
        "\n",
        "print('train set written to document')\n",
        "\n",
        "\n",
        "print('test data generated, writing test set to document')\n",
        "test_input, test_output, test_input_lengths = Dyck.training_set_generator (TEST_SIZE, MAX_SIZE + 2, 2 * MAX_SIZE)\n",
        "with open('Dyck1_Dataset_Suzgun_test.txt', 'a') as f:\n",
        "  for i in range(len(test_input)):\n",
        "    f.write(str(test_input[i])+','+str(test_output[i])+','+str(test_input_lengths[i])+'\\n')\n",
        "\n",
        "print('test set written to document')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MscWhMPW6CwQ",
        "outputId": "3461a810-16eb-42d4-a069-e98b1a276811"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "500 samples generated.\n",
            "1000 samples generated.\n",
            "1500 samples generated.\n",
            "2000 samples generated.\n",
            "2500 samples generated.\n",
            "3000 samples generated.\n",
            "3500 samples generated.\n",
            "4000 samples generated.\n",
            "4500 samples generated.\n",
            "5000 samples generated.\n",
            "5500 samples generated.\n",
            "6000 samples generated.\n",
            "6500 samples generated.\n",
            "7000 samples generated.\n",
            "7500 samples generated.\n",
            "8000 samples generated.\n",
            "8500 samples generated.\n",
            "9000 samples generated.\n",
            "9500 samples generated.\n",
            "10000 samples generated.\n",
            "training data generated, writing training set to document\n",
            "train set written to document\n",
            "test data generated, writing test set to document\n",
            "500 samples generated.\n",
            "1000 samples generated.\n",
            "1500 samples generated.\n",
            "2000 samples generated.\n",
            "2500 samples generated.\n",
            "3000 samples generated.\n",
            "3500 samples generated.\n",
            "4000 samples generated.\n",
            "4500 samples generated.\n",
            "5000 samples generated.\n",
            "test set written to document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_input[1])\n",
        "print(training_output[1])\n",
        "print(len(training_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWLmR9LO7SUg",
        "outputId": "52b5be9f-d628-415d-bdfd-8916e1db69f6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(((((()))((())))))\n",
            "111111111111111110\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_input[5])\n",
        "print(test_output[5])\n",
        "print(len(test_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md0mdF_IG3Nc",
        "outputId": "806cacd7-01c8-4fdf-eee0-c63399c82055"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(()(((((()((()))())))))((((((((()))))))(((())))((((()))))())))\n",
            "11111111111111111111111111111111111111111111111111111111111110\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_input[5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmd-0Kw1HmUG",
        "outputId": "498daf80-e429-4954-fd14-fbd0b50f62af"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Dyck.output_generator('(())()()'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isND8BAeH7T2",
        "outputId": "dd4eb86a-f453-45c8-a8ec-73ec964a0784"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11101010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('Dyck1_Dataset_Suzgun_train.txt', 'a') as f:\n",
        "#   for i in range(len(training_input)):\n",
        "#     f.write(training_input[i]+','+training_input_lengths][i]+','+)"
      ],
      "metadata": {
        "id": "efnuzHJoLN9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}